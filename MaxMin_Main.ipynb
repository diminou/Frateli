{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 15.   8.  21.   1.   8.   4.  12.   8.  18.  13.  17.  15.  10.   8.\n",
      "   11.]\n",
      " [ 16.   9.  21.  13.  13.   7.  26.  14.  20.   9.  16.  21.   8.   8.\n",
      "   16.]\n",
      " [ 11.   7.  12.  12.   7.   5.  10.  13.  11.   6.   5.  12.  11.   6.\n",
      "    6.]\n",
      " [ 11.  15.  19.  17.   6.   8.  15.  15.  24.  12.  13.  25.  11.   8.\n",
      "   10.]\n",
      " [ 12.   4.  18.  16.   9.   6.  10.   9.  10.   7.   5.   8.   4.   5.\n",
      "    5.]\n",
      " [ 16.  10.  24.  10.   6.   2.  16.   9.  18.  12.  12.  30.  12.  11.\n",
      "   15.]\n",
      " [ 16.   8.  23.   9.   7.   6.  16.  15.  14.   7.  13.  10.  11.   6.\n",
      "   10.]\n",
      " [ 19.   8.  25.  19.  11.   6.  18.  20.  18.  18.  17.  20.  12.  13.\n",
      "   16.]\n",
      " [ 12.   8.  24.   9.   6.   7.  13.   9.  14.  10.  14.  24.   5.  12.\n",
      "   16.]\n",
      " [  8.   8.   9.   6.   8.   5.   4.   9.  15.   8.   8.   5.  14.   2.\n",
      "    7.]]\n",
      "[6 5 3 3 6 4 6 3 6 2]\n"
     ]
    }
   ],
   "source": [
    "import MaxMin_library as mm\n",
    "import numpy as np\n",
    "import warnings\n",
    "#import pdb; pdb.set_trace()\n",
    "\n",
    "#np.random.seed(1253)\n",
    "\n",
    "S = 15 # n. students\n",
    "T = 10 # n. tutors\n",
    "n_subjects = 20\n",
    "n_different_values = 30\n",
    "n_students_per_tutor = np.random.randint(low=S/T+1, high=3*(S/T+1)+1, size=T)\n",
    "\n",
    "mm.check_input_consistency(S, T, n_students_per_tutor, n_subjects)\n",
    "\n",
    "Affinity = mm.generateAffinity(S, T, n_subjects, n_different_values)\n",
    "\n",
    "print(Affinity)\n",
    "print(n_students_per_tutor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1, 16.0), (6, 16.0), (9, 8.0)],\n",
       " [(0, 8.0), (5, 10.0), (6, 8.0)],\n",
       " [(7, 25.0), (8, 24.0), (4, 18.0)],\n",
       " [(3, 17.0), (1, 13.0), (4, 16.0)],\n",
       " [(0, 8.0), (2, 7.0), (4, 9.0)],\n",
       " [(3, 8.0), (8, 7.0), (1, 7.0)],\n",
       " [(1, 26.0), (2, 10.0), (0, 12.0)],\n",
       " [(0, 8.0), (2, 13.0), (4, 9.0)],\n",
       " [(0, 18.0), (4, 10.0), (8, 14.0)],\n",
       " [(7, 18.0), (4, 7.0), (6, 7.0)],\n",
       " [(0, 17.0), (5, 12.0), (8, 14.0)],\n",
       " [(5, 30.0), (6, 10.0), (8, 24.0)],\n",
       " [(9, 14.0), (5, 12.0), (6, 11.0)],\n",
       " [(3, 8.0), (7, 13.0), (8, 12.0)],\n",
       " [(1, 16.0), (6, 10.0)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_assignment = mm.MaxMinStudentTutorAssignment(Affinity, n_students_per_tutor)\n",
    "final_assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affinity_sorted = np.unique(np.reshape(Affinity[Affinity>0],(1,-1)))\n",
    "# feas_vec = []\n",
    "# #for tt in affinity_sorted:\n",
    "\n",
    "# Affinity_tmp = np.zeros(Affinity.shape)\n",
    "# Affinity_tmp[:] = Affinity\n",
    "# Affinity_tmp[(Affinity_tmp<affinity_sorted[29]).reshape(Affinity.shape)] = 0\n",
    "# feasible_flag, unassigned_students_tmp, min_affinity_tmp, tutor_student_assignment_tmp = \\\n",
    "#     mm.MaxFlow_FeasibilityProblem(S, T, n_students_per_tutor, Affinity_tmp)\n",
    "#feas_vec.append((tt,feasible_flag))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
